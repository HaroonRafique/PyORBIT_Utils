{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 0.03. This is the latest version.\n",
      "Please help me to improve it reporting bugs to guido.sterbini@cern.ch.\n",
      "Your platform is Linux-3.10.0-693.2.2.el7.x86_64-x86_64-with-redhat-6.9-Carbon\n",
      "Your folder is /eos/user/f/fasvesta/2017\n",
      "Your IP is 172.17.0.5\n",
      "2017-12-20 16:05:49\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/eos/user/s/sterbini/MD_ANALYSIS/public/')\n",
    "#sys.path.append('/eos/project/l/liu/Toolbox/')\n",
    "from myToolbox import *\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "%matplotlib inline\n",
    "plt.style.use('classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle     \n",
    "import numpy as np\n",
    "import pandas as pnd\n",
    "import platform \n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import Image, display, HTML\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# function for tomoscope postprocessing\n",
    "def extractProfile(fileName,NoB=1):\n",
    "    '''Give me the input file (.dat) of the tomogram and I will give you 2 output:\n",
    "        the deltaP_P and the the momentum distribution profile.\n",
    "    ''' \n",
    "\n",
    "    print('Treating file ' + fileName)\n",
    "    a=os.system('/eos/project/l/liu/Instrumentation/tomography/runofflinetomo ' + fileName)\n",
    "    \n",
    "    try:\n",
    "        myFiles_c=glob.glob(fileName[0:-4] + '/d0*.data')\n",
    "        myFiles_i=glob.glob(fileName[0:-4] + '/image0*.data')\n",
    "        if NoB==1:\n",
    "            convergence=np.loadtxt(myFiles_c[0])\n",
    "            image=np.loadtxt(myFiles_i[0])\n",
    "            with open(fileName[0:-4] + '/input_v2.dat','r') as stream: tomofileheader = stream.readlines()[:98]\n",
    "\n",
    "            myInput={'timestamp': np.int(tomofileheader[1]),\n",
    "                    'PLSUSER': tomofileheader[0][0:-1],\n",
    "                    'NumberOfframes': np.int(tomofileheader[16][0:-1]),\n",
    "                    'B_T': np.double(tomofileheader[75][0:-1]),\n",
    "                    'Bdot_T_per_s': np.double(tomofileheader[77][0:-1]),\n",
    "                    'machineRadius_m': np.double(tomofileheader[79][0:-1]),\n",
    "                    'bendingRadius_m': np.double(tomofileheader[81][0:-1]),\n",
    "                    'particleMass_eV': np.double(tomofileheader[85][0:-1]),\n",
    "                    'h': np.int(np.double(tomofileheader[69][0:-1])),\n",
    "                    'ctime': np.int(tomofileheader[2])\n",
    "            }\n",
    "\n",
    "            with open(fileName[0:-4] + '/plotinfo.data','r') as stream: tomofileheader = stream.readlines()\n",
    "\n",
    "            myInput['profilecount']=np.int(str.split(tomofileheader[1])[2])\n",
    "            myInput['profilelength']=np.int(str.split(tomofileheader[3])[2])\n",
    "\n",
    "            myInput['dtbin']=np.double(str.split(tomofileheader[5])[2])\n",
    "            myInput['dEbin']=np.double(str.split(tomofileheader[7])[2])\n",
    "            myInput['xat0']=np.double(str.split(tomofileheader[11])[2])\n",
    "            myInput['yat0']=np.double(str.split(tomofileheader[12])[2])\n",
    "            myInput['eperimage']=np.double(str.split(tomofileheader[9])[2])\n",
    "\n",
    "            mySpeedOfLight=299792458. #TODO\n",
    "            myInput['momentum_eV']=myInput['B_T']*myInput['bendingRadius_m']/(10/mySpeedOfLight*1e8)*1.e9 #TODO\n",
    "            myInput['totalEnergy_eV']=np.sqrt(myInput['momentum_eV']**2+myInput['particleMass_eV']**2)\n",
    "            myInput['gamma']=myInput['totalEnergy_eV']/myInput['particleMass_eV']\n",
    "            myInput['beta']=np.sqrt(1-1/myInput['gamma']**2)\n",
    "\n",
    "            image=image*myInput['eperimage']/myInput['dtbin']/myInput['dEbin']\n",
    "\n",
    "            halfProfileLength=myInput['profilelength']/2.\n",
    "\n",
    "            Toffset= (myInput['xat0']-halfProfileLength)*myInput['dtbin']*1e9\n",
    "            Eoffset= (myInput['yat0']-halfProfileLength)*myInput['dEbin']/1e6\n",
    "\n",
    "            t=np.arange(-halfProfileLength,halfProfileLength)*myInput['dtbin']*1e9-Toffset\n",
    "            E=np.arange(-halfProfileLength,halfProfileLength)*myInput['dEbin']/1e6-Eoffset\n",
    "\n",
    "            deltaP_P= 1/myInput['beta']**2*E*1e6/myInput['totalEnergy_eV']\n",
    "            myProfile=np.sum(np.reshape(image, [myInput['profilelength'], myInput['profilelength']]),0)\n",
    "            myProfile=myProfile/np.trapz(myProfile,deltaP_P)\n",
    "            myInput['deltaP_P']=deltaP_P;\n",
    "            myInput['myProfile']=myProfile;\n",
    "            myInput['E_MeV']=E\n",
    "            myInput['t_ns']=t\n",
    "            myInput['phaseSpace_e_per_eVs']=np.reshape(image, [myInput['profilelength'], myInput['profilelength']]);\n",
    "\n",
    "            myProfileNormalized=myProfile/np.trapz(myProfile,deltaP_P)\n",
    "\n",
    "            #rms emittance calculation\n",
    "            xbar = 0.\n",
    "            xms = 0.\n",
    "            ybar = 0.\n",
    "            yms = 0.\n",
    "            xybar = 0.\n",
    "\n",
    "            phaseSpaceNorm = myInput['phaseSpace_e_per_eVs'].T/np.sum(np.sum(myInput['phaseSpace_e_per_eVs'].T))\n",
    "\n",
    "            for i in xrange(0,myInput['profilelength']):\n",
    "                for j in xrange(0,myInput['profilelength']):\n",
    "                    xbar += phaseSpaceNorm[i,j]*i\n",
    "                    xms += phaseSpaceNorm[i,j]*i**2\n",
    "                    ybar += phaseSpaceNorm[i,j]*j\n",
    "                    yms += phaseSpaceNorm[i,j]*j**2\n",
    "                    xybar += phaseSpaceNorm[i,j]*i*j\n",
    "\n",
    "            myInput['rmsemittance'] = np.pi * myInput['dtbin'] * myInput['dEbin'] * np.sqrt((xms - xbar**2)*(yms - ybar**2) - (xybar -xbar*ybar)**2)    \n",
    "\n",
    "            myMean=np.trapz(deltaP_P*myProfileNormalized,deltaP_P)   \n",
    "            myRMS=np.sqrt(np.trapz((deltaP_P-myMean)**2*myProfileNormalized,deltaP_P))\n",
    "            myInput['deltaP_P_RMS']=myRMS\n",
    "\n",
    "            return myInput\n",
    "    except:\n",
    "        print ('Failed in '+ fileName)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fromMatlabToDataFrame(listing, listOfVariableToAdd, verbose=False, matlabFullInfo=False):\n",
    "    listOfVariableToAdd=list(set(listOfVariableToAdd))\n",
    "    myDataFrame=pnd.DataFrame({})\n",
    "    cycleStamp=[]\n",
    "    cycleStampHuman=[]\n",
    "    PLS_matlab=[]\n",
    "    matlabObject=[]\n",
    "    matlabFilePath=[]\n",
    "    for j in listOfVariableToAdd:\n",
    "        exec(j.replace('.','_')+'=[]')\n",
    "    for i in listing:\n",
    "        if verbose:\n",
    "            print(i)\n",
    "        data=myToolbox.japcMatlabImport(i);\n",
    "        if matlabFullInfo:\n",
    "            matlabObject.append(data)\n",
    "        #to correct\n",
    "        localCycleStamp=np.nanmax(data.headerCycleStamps);\n",
    "        deltaLocal_UTC=datetime.datetime.fromtimestamp(localCycleStamp/1e9)-datetime.datetime.utcfromtimestamp(localCycleStamp/1e9)\n",
    "        utcCycleStamp=localCycleStamp+deltaLocal_UTC.total_seconds()*1e9\n",
    "        cycleStamp.append(utcCycleStamp)\n",
    "        aux=myToolbox.unixtime2datetimeVectorize(np.nanmax(data.headerCycleStamps)/1e9)\n",
    "        cycleStampHuman.append(aux.tolist())\n",
    "        PLS_matlab.append(data.cycleName)\n",
    "        matlabFilePath.append(os.path.abspath(i))\n",
    "        for j in listOfVariableToAdd:\n",
    "            if hasattr(data,j.split('.')[0]):\n",
    "                exec(j.replace('.','_') + '.append(data.' + j + ')')\n",
    "            else:\n",
    "                exec(j.replace('.','_') + '.append(np.nan)')\n",
    "    myDataFrame['cycleStamp']=pnd.Series(cycleStamp,cycleStampHuman)\n",
    "    myDataFrame['matlabPLS']=pnd.Series(PLS_matlab,cycleStampHuman)\n",
    "    myDataFrame['matlabFilePath']=pnd.Series(matlabFilePath,cycleStampHuman)\n",
    "    if matlabFullInfo:\n",
    "        myDataFrame['matlabFullInfo']=pnd.Series(matlabObject,cycleStampHuman)\n",
    "    for j in listOfVariableToAdd:\n",
    "        exec('myDataFrame[\\'' + j + '\\']=pnd.Series(' +j.replace('.','_')+ ',cycleStampHuman)')    #myDataFrame=pnd.DataFrame({j:aux,\n",
    "    return myDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_5_parameters(x, c, m, A, mu, sig):\n",
    "    \"\"\"gaussian_5_parameter(x, c, m, A, mu, sig)\"\"\"\n",
    "    return c+m*x+A/np.sqrt(2*np.pi)/sig*np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeGaussianFit_5_parameters(X,Y,for_df=False):\n",
    "    try:      \n",
    "        i = np.where( (X>min(X)+10) & (X<max(X)-10) )\n",
    "        #i = np.where( (Y>1.01*min(Y)) & (Y<0.99*max(Y)) )\n",
    "        X = X[i]\n",
    "        Y = Y[i]\n",
    "        indx_max = np.argmax(Y)\n",
    "        mu0 = X[indx_max]\n",
    "        window = 2*100\n",
    "        x_tmp = X[indx_max-window:indx_max+window]\n",
    "        y_tmp = Y[indx_max-window:indx_max+window]\n",
    "        offs0 = min(y_tmp)\n",
    "        ampl = max(y_tmp)-offs0\n",
    "        x1 = x_tmp[np.searchsorted(y_tmp[:window], offs0+ampl/2)]\n",
    "        x2 = x_tmp[np.searchsorted(-y_tmp[window:], -offs0+ampl/2)]\n",
    "        FWHM = x2-x1\n",
    "        sigma0 = np.abs(2*FWHM/2.355)\n",
    "        ampl *= np.sqrt(2*np.pi)*sigma0\n",
    "        slope = 0\n",
    "        popt,pcov = curve_fit(gaussian_5_parameters,X,Y,p0=[offs0,slope,ampl,mu0,sigma0])\n",
    "        if for_df:\n",
    "            return popt[0], popt[3], popt[4]\n",
    "        else:    \n",
    "            return {'c': popt[0], 'm': popt[1],'A': popt[2], 'mu': popt[3], 'sig': popt[4], 'pcov': pcov, 'p': popt}\n",
    "    except:\n",
    "        if for_df:\n",
    "            return np.nan,np.nan, np.nan\n",
    "        else:\n",
    "            return {k: np.nan for k in ['c', 'm','A', 'mu', 'sig', 'pcov', 'p']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PS_WSoptics(tunex, tuney, WS='64'):\n",
    "    qv, qh, wire, betx, bety, dx, dy= np.loadtxt('/eos/user/f/fasvesta/optic_values.dat', dtype=([('qv',float),('qh',float),('wire',float),('betx',float),('bety',float),('dx',float),('dy',float)]),comments='#',unpack=True)\n",
    "    startindx = {'54' :0, '64': 64, '65': 128, '68': 192, '85':256}\n",
    "    stopindx = {'54' :64, '64': 128, '65': 192, '68': 256, '85':320}\n",
    "    bx = betx[startindx[WS]:stopindx[WS]]\n",
    "    by = bety[startindx[WS]:stopindx[WS]]\n",
    "    Dx = dx[startindx[WS]:stopindx[WS]]\n",
    "    qh1=qh[startindx[WS]:stopindx[WS]]\n",
    "    qv1=qv[startindx[WS]:stopindx[WS]]\n",
    "    betax = scipy.interpolate.interp2d(qh1,qv1,bx)\n",
    "    betay = scipy.interpolate.interp2d(qh1,qv1,by)\n",
    "    dispx = scipy.interpolate.interp2d(qh1,qv1,Dx)\n",
    "    result ={'Beta_x':betax(tunex,tuney), 'Beta_y':betay(tunex,tuney),'D_x': dispx(tunex,tuney)}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_5(x, c, m, A, mu, sig):\n",
    "    \"\"\"gaussian_5_parameter(x, c, m, A, mu, sig)\"\"\"\n",
    "    return c+m*x+A*np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "myDoubleGauss = lambda x,offs0,slope,mu,ampl1,sigma1,ampl2,sigma2: offs0+ x*slope + ampl1*np.exp(-(x-mu)**2/(2*sigma1**2)) + ampl2*np.exp(-(x-mu)**2/(2*sigma2**2))\n",
    "def makeDoubleGaussianFit(X,Y):\n",
    "    try:     \n",
    "        i = np.where( (X>min(X)+10) & (X<max(X)-10) )\n",
    "        X = X[i]\n",
    "        Y = Y[i]\n",
    "        indx_max = np.argmax(Y)\n",
    "        mu0 = X[indx_max]\n",
    "        window = 2*100\n",
    "        x_tmp = X[indx_max-window:indx_max+window]\n",
    "        y_tmp = Y[indx_max-window:indx_max+window]\n",
    "        offs0 = min(y_tmp)\n",
    "        ampl = max(y_tmp)-offs0\n",
    "        x1 = x_tmp[np.searchsorted(y_tmp[:window], offs0+ampl/2)]\n",
    "        x2 = x_tmp[np.searchsorted(-y_tmp[window:], -offs0+ampl/2)]\n",
    "        FWHM = x2-x1\n",
    "        sigma0 = np.abs(2*FWHM/2.355)\n",
    "        ampl *= np.sqrt(2*np.pi)*sigma0\n",
    "        slope = 0\n",
    "        popt,pcov = curve_fit(myDoubleGauss,X,Y,p0=[offs0,slope,mu0,ampl,sigma0,0,max(X)])\n",
    "        if abs(popt[4])<abs(popt[6]):\n",
    "            A1 = popt[3]\n",
    "            sig1 = abs(popt[4])\n",
    "            A2 = popt[5]\n",
    "            sig2 = abs(popt[6])\n",
    "        else:\n",
    "            A1 = popt[5]\n",
    "            sig1 = abs(popt[6])\n",
    "            A2 = popt[3]\n",
    "            sig2 = abs(popt[4])\n",
    "        return {'c': popt[0], 'm': popt[1], 'mu': popt[2], 'A1': A1, 'sig1': sig1, 'A2': A2, 'sig2': sig2, 'pcov': pcov, 'p': popt}\n",
    "    except:\n",
    "        return {k: np.nan for k in ['c', 'm', 'mu', 'A1', 'sig1', 'A2', 'sig2','pcov', 'p']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(year=2017,month=7,date=18,hour=8,minutes=0,span=10,user='CPS%MD3',WS='85.V'):\n",
    "    t1=datetime.datetime(year,month,date,hour,minutes)\n",
    "    t2=t1+datetime.timedelta(hours=span)\n",
    "    CALS=['PR.BWS.{}_ROT:PROF_DATA_IN'.format(WS),  'PR.BWS.{}_ROT:PROF_POSITION_IN'.format(WS),  'PR.BWS.{}_ROT:ACQ_DELAY'.format(WS)]\n",
    "    df=myToolbox.fromTimberToDataFrame(CALS,t1,t2,fundamental=user)\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_psb_data(year=2017,month=21,date=11,hour=8,minutes=0,span=10,user='PSB%MD4',plane='V'):\n",
    "    t1=datetime.datetime(year,month,date,hour,minutes)\n",
    "    t2=t1+datetime.timedelta(hours=span)\n",
    "    CALS=['BR3.BWS.2L1.'+plane+'_ROT:PROF_POSITION_IN', 'BR3.BWS.2L1.'+plane+'_ROT:PROF_DATA_IN']\n",
    "    df=myToolbox.fromTimberToDataFrame(CALS,t1,t2,fundamental=user)\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emittance_psb(ndf,plane='V',myFiles=None,dp=1.03e-3):\n",
    "    betagamma=2.267\n",
    "    bx=5.699\n",
    "    by=4.25\n",
    "    dx=1.466\n",
    "    df=ndf.copy()\n",
    "    a=df.columns\n",
    "    if 'emittance '+plane not in a:\n",
    "        df['emittance '+plane]=np.nan\n",
    "    if 'sig '+plane not in a:\n",
    "        df=profiles_psb(df,plane=plane)\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    if plane=='V':\n",
    "        df['emittance V'].iloc[span]=betagamma*(df['sig V'].iloc[span]**2)/by\n",
    "    else:\n",
    "        df['emittance H'].iloc[span]=betagamma*(df['sig H'].iloc[span]**2-(dx*1000)**2*dp**2)/bx\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emittance(ndf,WS='85.V',myFiles=None,beta=0.91444281513833,gamma=2.4708737618826,dp=1e-3,Qx=6.20,Qy=6.24):\n",
    "    df=ndf.copy()\n",
    "    a=df.columns\n",
    "    if 'emittance' not in a:\n",
    "        df['emittance']=np.nan\n",
    "    if 'sig' not in a:\n",
    "        df=profiles(df,WS=WS)\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    if 'WP' not in a:\n",
    "        df['WP']=np.nan\n",
    "    df['WP'][span]='Qx={} Qy={}'.format(str(Qx),str(Qy))\n",
    "    if WS[-1]=='V':\n",
    "        df['emittance V'].iloc[span]=beta*gamma*(df['sig'].iloc[span]**2)/PS_WSoptics(Qx,Qy,WS=WS[:-2])['Beta_y']\n",
    "    else:\n",
    "        df['emittance H'].iloc[span]=beta*gamma*(df['sig'].iloc[span]**2-(PS_WSoptics(Qx,Qy,WS=WS[:-2])['D_x']*1000)**2*dp**2)/PS_WSoptics(Qx,Qy,WS=WS[:-2])['Beta_x']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def twiss(ndf,WS='85.V',myFiles=None):\n",
    "    df=ndf.copy()\n",
    "    a=df.columns\n",
    "    if 'betx' not in a:\n",
    "        df['betx']=np.nan\n",
    "    if 'bety' not in a:\n",
    "         df['bety']=np.nan\n",
    "    if 'dx' not in a:\n",
    "         df['dx']=np.nan\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    for i in span:\n",
    "            df.loc[df.index[i],'betx']=PS_WSoptics(df['Qx'].iloc[i],df['Qy'].iloc[i],WS=WS[:-2])['Beta_x']\n",
    "            df.loc[df.index[i],'dx']=PS_WSoptics(df['Qx'].iloc[i],df['Qy'].iloc[i],WS=WS[:-2])['D_x']\n",
    "            df.loc[df.index[i],'bety']=PS_WSoptics(df['Qx'].iloc[i],df['Qy'].iloc[i],WS=WS[:-2])['Beta_y']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emittance_df(ndf,WS='85.V',myFiles=None,beta=0.91444281513833,gamma=2.4708737618826,dp=1e-3):\n",
    "    df=ndf.copy()\n",
    "    a=df.columns\n",
    "    if 'emittance V' not in a:\n",
    "        df['emittance V']=np.nan\n",
    "    if 'emittance H' not in a:\n",
    "        df['emittance H']=np.nan\n",
    "    if 'sig V' not in a:\n",
    "        df=profiles(df,WS=WS)\n",
    "    if 'sig H' not in a:\n",
    "        df=profiles(df,WS=WS)\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    if WS[-1]=='V':\n",
    "        for i in span:\n",
    "            df.loc[df.index[i],'emittance V']=beta*gamma*(df['sig V'].iloc[i]**2)/PS_WSoptics(df['Qx'].iloc[i],df['Qy'].iloc[i],WS=WS[:-2])['Beta_y']\n",
    "    else:\n",
    "        for i in span:\n",
    "            df.loc[df.index[i],'emittance H']=beta*gamma*(df['sig H'].iloc[i]**2-(PS_WSoptics(df['Qx'].iloc[i],df['Qy'].iloc[i],WS=WS[:-2])['D_x']*1000)**2*dp**2)/PS_WSoptics(df['Qx'].iloc[i],df['Qy'].iloc[i],WS=WS[:-2])['Beta_x']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emittance_dp(ndf,WS='54.H',myFiles=None,beta=0.91444281513833,gamma=2.4708737618826):\n",
    "    df=ndf.copy()\n",
    "    a=df.columns\n",
    "    if 'emittance dp H' not in a:\n",
    "        df['emittance dp H']=np.nan\n",
    "    if 'sig H' not in a:\n",
    "        df=profiles(df,WS=WS)\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    for i in span:\n",
    "        df.loc[df.index[i],'emittance dp H']=beta*gamma*(df['sig H'].iloc[i]**2-(PS_WSoptics(df['Qx'].iloc[i],df['Qy'].iloc[i],WS=WS[:-2])['D_x']*1000)**2*df['deltaP_P_RMS'].iloc[i]**2)/PS_WSoptics(df['Qx'].iloc[i],df['Qy'].iloc[i],WS=WS[:-2])['Beta_x']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PS_WS_beta={'85.V':12.35,'64.V':22.67,'65.H':20.11,'68.H':13.26,'54.H':12.48}\n",
    "PS_WS_app={'85.V':11.83,'64.V':22.04,'65.H':22.33,'68.H':12.62,'54.H':None}\n",
    "PS_WS_D={'68.H':2.37,'65.H':3.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intensity(myFiles,Qx=6.20,Qy=6.24):\n",
    "    df=fromMatlabToDataFrame(myFiles,['PR_BCT_ST.Samples.value.samples'])\n",
    "    def losses(a):\n",
    "        try:\n",
    "            b=(a[85]-a[1185])/a[85]*100 \n",
    "            if b<0:\n",
    "                print '85=',a[85],'1185=',a[1185]\n",
    "        except:\n",
    "            b=np.nan\n",
    "        return b\n",
    "    def ratio(a):\n",
    "        try:\n",
    "            c=a[1185]/a[85]\n",
    "        except:\n",
    "            c=np.nan\n",
    "        return c\n",
    "    df['WP']='Qx={} Qy={}'.format(str(Qx),str(Qy))\n",
    "    df['losses']=df['PR_BCT_ST.Samples.value.samples'].apply(losses)\n",
    "    df['ratio']=df['PR_BCT_ST.Samples.value.samples'].apply(ratio)\n",
    "    return df\n",
    "def intensity_df(ndf):\n",
    "    df=ndf.copy()\n",
    "    def losses(a):\n",
    "        try:\n",
    "            b=(a[85]-a[1085])/a[85]*100 \n",
    "        except:\n",
    "            b=np.nan\n",
    "        return b\n",
    "    def ratio(a):\n",
    "        try:\n",
    "            c=a[1085]/a[85]\n",
    "        except:\n",
    "            c=np.nan\n",
    "        return c\n",
    "    df['losses']=df['PR_BCT_ST.Samples.value.samples'].apply(losses)\n",
    "    df['ratio']=df['PR_BCT_ST.Samples.value.samples'].apply(ratio)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def profiles_psb(ndf,plane='V',myFiles=None):\n",
    "    df=ndf.copy()\n",
    "    x=np.linspace(-40,40,1000)\n",
    "    a=df.columns\n",
    "    if 'profile '+plane not in a:\n",
    "        df['profile '+plane]=df['BR3.BWS.2L1.'+plane+'_ROT:PROF_DATA_IN'].apply(filtered)\n",
    "        df['position '+plane]=df['BR3.BWS.2L1.'+plane+'_ROT:PROF_POSITION_IN'].values/1000.        \n",
    "    if 'sig '+plane not in a:\n",
    "        df['sig '+plane]=np.nan\n",
    "        df['mu '+plane]=np.nan\n",
    "        df['c '+plane]=np.nan\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    if np.isnan(df['sig '+plane].iloc[span]).all():\n",
    "        for i in span:\n",
    "            df['c '+plane].iloc[i],df['mu '+plane].iloc[i],df['sig '+plane].iloc[i]=makeGaussianFit_5_parameters(df['position '+plane].iloc[i],df['profile '+plane].iloc[i],for_df=True)\n",
    "            try:\n",
    "                yz=scipy.interpolate.interp1d(df['position '+plane].iloc[i]-df['mu '+plane].iloc[i],df['profile '+plane].iloc[i]-df['c '+plane].iloc[i])(x)\n",
    "                if np.isnan(yz[0]):\n",
    "                    yz=np.nan\n",
    "            except:\n",
    "                yz = np.nan\n",
    "            df['profile '+plane].iloc[i]=yz\n",
    "            df['position '+plane].iloc[i]=x\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filtered(a):\n",
    "    b=(scipy.signal.savgol_filter(a,15,1))\n",
    "    return b\n",
    "def profiles(ndf,WS='85.V',myFiles=None):\n",
    "    df=ndf.copy()\n",
    "    x=np.linspace(-40,40,1000)\n",
    "    a=df.columns\n",
    "    if 'profile '+WS[-1] not in a:\n",
    "        df['profile '+WS[-1]]=df['PR.BWS.{}_ROT:PROF_DATA_IN'.format(WS)].apply(filtered)\n",
    "        df['position '+WS[-1]]=df['PR.BWS.{}_ROT:PROF_POSITION_IN'.format(WS)].values/1000.\n",
    "    if 'sig '+WS[-1] not in a:\n",
    "        df['sig '+WS[-1]]=np.nan\n",
    "        df['mu '+WS[-1]]=np.nan\n",
    "        df['c '+WS[-1]]=np.nan\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    if np.isnan(df['sig '+WS[-1]].iloc[span]).all():\n",
    "        for i in span:\n",
    "            df['c '+WS[-1]].iloc[i],df['mu '+WS[-1]].iloc[i],df['sig '+WS[-1]].iloc[i]=makeGaussianFit_5_parameters(df['position '+WS[-1]].iloc[i],df['profile '+WS[-1]].iloc[i],for_df=True)\n",
    "            try:\n",
    "                yz=scipy.interpolate.interp1d(df['position '+WS[-1]].iloc[i]-df['mu '+WS[-1]].iloc[i],df['profile '+WS[-1]].iloc[i]-df['c '+WS[-1]].iloc[i])(x)\n",
    "                if np.isnan(yz[0]):\n",
    "                    yz=np.nan\n",
    "            except:\n",
    "                yz = np.nan\n",
    "            df['profile '+WS[-1]].iloc[i]=yz\n",
    "            df['position '+WS[-1]].iloc[i]=x\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def span_range(df,myFiles=None):\n",
    "    if myFiles:\n",
    "        span=[i for i in xrange(len(df)) if datetime.datetime.strptime(myFiles[0][-27:-4], '%Y.%m.%d.%H.%M.%S.%f')<df.index[i]<datetime.datetime.strptime(myFiles[-1][-27:-4], '%Y.%m.%d.%H.%M.%S.%f')]\n",
    "    else:\n",
    "        span=xrange(len(df))\n",
    "    return span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def second_moment(ndf,WS='85.V',myFiles=None,n_sigmas=4):\n",
    "    df=ndf.copy()\n",
    "    a=df.columns\n",
    "    plane = WS[-1]\n",
    "    fig=plt.figure()\n",
    "    #if plane == 'H':\n",
    "    if 'second_moment '+plane not in a:\n",
    "        df['second_moment '+plane]=np.nan\n",
    "    if 'profile '+plane not in a:\n",
    "        df=profiles(df,WS=WS,myFiles=myFiles)\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    for i in span:\n",
    "        try:\n",
    "            a=np.array(zip(df.loc[df.index[i],'position '+plane],df.loc[df.index[i],'profile '+plane]))     \n",
    "            c=[j for j in np.where(a[:,0]<(n_sigmas+0.5)*df['sig '+plane].iloc[i])[0] if j in np.where(a[:,0]>n_sigmas*df['sig '+plane].iloc[i])[0]]\n",
    "            d=np.mean(a[:,1][c])\n",
    "            c=[j for j in np.where(a[:,0]>-(n_sigmas+0.5)*df['sig '+plane].iloc[i])[0] if j in np.where(a[:,0]<-n_sigmas*df['sig '+plane].iloc[i])[0]]\n",
    "            d1=np.mean(a[:,1][c])\n",
    "            b=[j for j in np.where(a[:,0]<n_sigmas*df['sig '+plane].iloc[i])[0] if j in np.where(a[:,0]>-n_sigmas*df['sig '+plane].iloc[i])[0]]\n",
    "            a[:,1]-=np.nanmean([d,d1])\n",
    "            plt.plot(a[:,0][b],a[:,1][b])\n",
    "            W=sum(a[:,1][b])\n",
    "            m=a[:,0][b]*a[:,1][b]\n",
    "            M=sum(m)/W\n",
    "            s=a[:,1][b]*(a[:,0][b]-M)**2\n",
    "            S=np.sqrt(sum(s)/W)\n",
    "            df.loc[df.index[i],'second_moment '+plane]=S  \n",
    "            #print sum(s),W\n",
    "        except:\n",
    "            df.loc[df.index[i],'second_moment '+plane]=np.nan\n",
    "    #plt.xlim(-4*dfh['sig'].mean(),4*dfh['sig'].mean())\n",
    "    #plt.ylim(-0.1,0.7)\n",
    "    return df ,fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
